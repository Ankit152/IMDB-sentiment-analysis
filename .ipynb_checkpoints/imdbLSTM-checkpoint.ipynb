{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMDB Sentiment Analysis using LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split as tts\n",
    "from keras.layers import Dense, LSTM,Embedding, SpatialDropout1D\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv('IMDB-Dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['review', 'sentiment'], dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# columns of the dataset\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# shape of the data\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5 elements from the top\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "# removing the html tags\n",
    "def clean_html(text):\n",
    "    clean=re.compile('<.*?>')\n",
    "    cleantext=re.sub(clean,'',text)\n",
    "    return cleantext\n",
    "    \n",
    "# first round of cleaning\n",
    "def clean_text1(text):\n",
    "    text=text.lower()\n",
    "    text=re.sub('\\[.*?\\]','',text)\n",
    "    text=re.sub('[%s]'%re.escape(string.punctuation),'',text)\n",
    "    text=re.sub('\\w*\\d\\w*','',text)\n",
    "    return text\n",
    "\n",
    "# second round of cleaning\n",
    "def clean_text2(text):\n",
    "    text=re.sub('[''\"\",,,]','',text)\n",
    "    text=re.sub('\\n','',text)\n",
    "    return text\n",
    "    \n",
    "cleaned_html=lambda x:clean_html(x)\n",
    "cleaned1=lambda x:clean_text1(x)\n",
    "cleaned2=lambda x:clean_text2(x)\n",
    "\n",
    "data['review']=pd.DataFrame(data.review.apply(cleaned_html))\n",
    "data['review']=pd.DataFrame(data.review.apply(cleaned1))\n",
    "data['review']=pd.DataFrame(data.review.apply(cleaned2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features=5000\n",
    "tokenizer = Tokenizer(num_words=max_features, split=' ')\n",
    "tokenizer.fit_on_texts(data['review'].values)\n",
    "X = tokenizer.texts_to_sequences(data['review'].values)\n",
    "X = pad_sequences(X,maxlen=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 600, 128)          640000    \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d (SpatialDr (None, 600, 128)          0         \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 128)               131584    \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 2)                 258       \n",
      "=================================================================\n",
      "Total params: 771,842\n",
      "Trainable params: 771,842\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "embed_dim = 128\n",
    "lstm_out = 128\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, embed_dim,input_length = X.shape[1]))\n",
    "model.add(SpatialDropout1D(0.4))\n",
    "model.add(LSTM(lstm_out, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(2,activation='softmax'))\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer='adam',metrics = ['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y=pd.get_dummies(data['sentiment']).values\n",
    "X_train, X_test, Y_train, Y_test = tts(X,Y, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/16\n",
      "625/625 [==============================] - 334s 535ms/step - loss: 0.4154 - accuracy: 0.8113 - val_loss: 0.3124 - val_accuracy: 0.8726\n",
      "Epoch 2/16\n",
      "625/625 [==============================] - 334s 535ms/step - loss: 0.3019 - accuracy: 0.8787 - val_loss: 0.3368 - val_accuracy: 0.8538\n",
      "Epoch 3/16\n",
      "625/625 [==============================] - 351s 561ms/step - loss: 0.2543 - accuracy: 0.8992 - val_loss: 0.2904 - val_accuracy: 0.8765\n",
      "Epoch 4/16\n",
      "625/625 [==============================] - 358s 573ms/step - loss: 0.2319 - accuracy: 0.9091 - val_loss: 0.2862 - val_accuracy: 0.8833\n",
      "Epoch 5/16\n",
      "625/625 [==============================] - 356s 570ms/step - loss: 0.2074 - accuracy: 0.9194 - val_loss: 0.2974 - val_accuracy: 0.8849\n",
      "Epoch 6/16\n",
      "625/625 [==============================] - 343s 549ms/step - loss: 0.2038 - accuracy: 0.9204 - val_loss: 0.2967 - val_accuracy: 0.8909\n",
      "Epoch 7/16\n",
      "625/625 [==============================] - 350s 560ms/step - loss: 0.1867 - accuracy: 0.9281 - val_loss: 0.2855 - val_accuracy: 0.8913\n",
      "Epoch 8/16\n",
      "625/625 [==============================] - 357s 571ms/step - loss: 0.1598 - accuracy: 0.9397 - val_loss: 0.3013 - val_accuracy: 0.8797\n",
      "Epoch 9/16\n",
      "625/625 [==============================] - 368s 588ms/step - loss: 0.1806 - accuracy: 0.9297 - val_loss: 0.3222 - val_accuracy: 0.8867\n",
      "Epoch 10/16\n",
      "625/625 [==============================] - 343s 549ms/step - loss: 0.1425 - accuracy: 0.9464 - val_loss: 0.3450 - val_accuracy: 0.8837\n",
      "Epoch 11/16\n",
      "625/625 [==============================] - 342s 547ms/step - loss: 0.1361 - accuracy: 0.9488 - val_loss: 0.3302 - val_accuracy: 0.8882\n",
      "Epoch 12/16\n",
      "625/625 [==============================] - 333s 532ms/step - loss: 0.1183 - accuracy: 0.9573 - val_loss: 0.3581 - val_accuracy: 0.8798\n",
      "Epoch 13/16\n",
      "625/625 [==============================] - 344s 551ms/step - loss: 0.1141 - accuracy: 0.9582 - val_loss: 0.3446 - val_accuracy: 0.8886\n",
      "Epoch 14/16\n",
      "625/625 [==============================] - 338s 541ms/step - loss: 0.1071 - accuracy: 0.9614 - val_loss: 0.4163 - val_accuracy: 0.8819\n",
      "Epoch 15/16\n",
      "625/625 [==============================] - 350s 560ms/step - loss: 0.1035 - accuracy: 0.9636 - val_loss: 0.3749 - val_accuracy: 0.8871\n",
      "Epoch 16/16\n",
      "625/625 [==============================] - 361s 578ms/step - loss: 0.0869 - accuracy: 0.9695 - val_loss: 0.4013 - val_accuracy: 0.8839\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1b390a75d08>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 64\n",
    "model.fit(X_train, Y_train, epochs = 16, batch_size=batch_size,validation_data=(X_test,Y_test),verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
